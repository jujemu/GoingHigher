{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n5b_bPwqOWY"
      },
      "source": [
        "![dataset_info.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q8-UeqUXHmC"
      },
      "outputs": [],
      "source": [
        "path_drive = '/content/drive/MyDrive/Colab Notebooks/GoingDeeper/6'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VPNNJWlWuUK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from PIL import Image, ImageDraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2fjkMAA_1EY"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import glob\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mZD9pbvpe3t"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clokpeFoC51m"
      },
      "outputs": [],
      "source": [
        "random_seed = 1234\n",
        "\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16IK6Gp6GVR0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "# plt.style.use('default')\n",
        "plt.style.use('seaborn')\n",
        "mpl.rcParams['figure.figsize'] = (10, 10)\n",
        "mpl.rcParams['xtick.labelbottom'] = False\n",
        "mpl.rcParams['ytick.labelleft'] = False\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams.update({'figure.autolayout': True})\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y83dB3BolUQA"
      },
      "outputs": [],
      "source": [
        "# this code is for not printing warning error info\n",
        "# 0 = all messages are logged (default behavior)\n",
        "# 1 = INFO messages are not printed\n",
        "# 2 = INFO and WARNING messages are not printed\n",
        "# 3 = INFO, WARNING, and ERROR messages are not printed\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mCXgSHoW8jW"
      },
      "outputs": [],
      "source": [
        "path = path_drive + '/data'\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    'kitti',\n",
        "    data_dir=path,\n",
        "    split=['train', 'test'],\n",
        "    shuffle_files=True,\n",
        "    with_info=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT_OHBhQX5n6",
        "outputId": "37471c1b-2725-4fbf-8c9d-0ee61adb98b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='kitti',\n",
              "    version=3.2.0,\n",
              "    description='Kitti contains a suite of vision tasks built using an autonomous driving\n",
              "platform. The full benchmark contains many tasks such as stereo, optical flow,\n",
              "visual odometry, etc. This dataset contains the object detection dataset,\n",
              "including the monocular images and bounding boxes. The dataset contains 7481\n",
              "training images annotated with 3D bounding boxes. A full description of the\n",
              "annotations can be found in the readme of the object development kit readme on\n",
              "the Kitti homepage.',\n",
              "    homepage='http://www.cvlibs.net/datasets/kitti/',\n",
              "    features=FeaturesDict({\n",
              "        'image': Image(shape=(None, None, 3), dtype=tf.uint8),\n",
              "        'image/file_name': Text(shape=(), dtype=tf.string),\n",
              "        'objects': Sequence({\n",
              "            'alpha': tf.float32,\n",
              "            'bbox': BBoxFeature(shape=(4,), dtype=tf.float32),\n",
              "            'dimensions': Tensor(shape=(3,), dtype=tf.float32),\n",
              "            'location': Tensor(shape=(3,), dtype=tf.float32),\n",
              "            'occluded': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
              "            'rotation_y': tf.float32,\n",
              "            'truncated': tf.float32,\n",
              "            'type': ClassLabel(shape=(), dtype=tf.int64, num_classes=8),\n",
              "        }),\n",
              "    }),\n",
              "    total_num_examples=7481,\n",
              "    splits={\n",
              "        'test': 711,\n",
              "        'train': 6347,\n",
              "        'validation': 423,\n",
              "    },\n",
              "    supervised_keys=None,\n",
              "    citation=\"\"\"@inproceedings{Geiger2012CVPR,\n",
              "      author = {Andreas Geiger and Philip Lenz and Raquel Urtasun},\n",
              "      title = {Are we ready for Autonomous Driving? The KITTI Vision Benchmark Suite},\n",
              "      booktitle = {Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
              "      year = {2012}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ds_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8vBvcpEpkLJ"
      },
      "outputs": [],
      "source": [
        "def visualize_bbox(input_image, object_bbox):\n",
        "    input_image = copy.deepcopy(input_image)\n",
        "    draw = ImageDraw.Draw(input_image)\n",
        "    \n",
        "    # 바운딩 박스 좌표(x_min, x_max, y_min, y_max) 구하기\n",
        "    width, height = img.size\n",
        "    x_min = object_bbox[:,1] * width\n",
        "    x_max = object_bbox[:,3] * width\n",
        "    y_min = height - object_bbox[:,0] * height\n",
        "    y_max = height - object_bbox[:,2] * height\n",
        "    \n",
        "    # 바운딩 박스 그리기\n",
        "    rects = np.stack([x_min, y_min, x_max, y_max], axis=1)\n",
        "    for _rect in rects:\n",
        "        draw.rectangle(_rect, outline=(255,0,0), width=2)\n",
        "\n",
        "    return input_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2M1nCpIr7jq"
      },
      "outputs": [],
      "source": [
        "def swap_xy(boxes):\n",
        "    return tf.stack([boxes[:, 1], boxes[:, 0], boxes[:, 3], boxes[:, 2]], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhvvHayGsHxU"
      },
      "outputs": [],
      "source": [
        "def random_flip_horizontal(image, boxes):\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        boxes = tf.stack(\n",
        "           [1 - boxes[:, 2], boxes[:, 1], 1 - boxes[:, 0], boxes[:, 3]], axis=-1\n",
        "        )\n",
        "        \n",
        "    return image, boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKzSc8F4sJA1"
      },
      "outputs": [],
      "source": [
        "def resize_and_pad_image(image, training=True):\n",
        "\n",
        "    min_side = 800.0\n",
        "    max_side = 1333.0\n",
        "    min_side_range = [640, 1024]\n",
        "    stride = 128.0\n",
        "    \n",
        "    image_shape = tf.cast(tf.shape(image)[:2], dtype=tf.float32)\n",
        "    if training:\n",
        "        min_side = tf.random.uniform((), min_side_range[0], min_side_range[1], dtype=tf.float32)\n",
        "    ratio = min_side / tf.reduce_min(image_shape)\n",
        "    if ratio * tf.reduce_max(image_shape) > max_side:\n",
        "        ratio = max_side / tf.reduce_max(image_shape)\n",
        "    image_shape = ratio * image_shape\n",
        "    image = tf.image.resize(image, tf.cast(image_shape, dtype=tf.int32))\n",
        "    padded_image_shape = tf.cast(\n",
        "        tf.math.ceil(image_shape / stride) * stride, dtype=tf.int32\n",
        "    )\n",
        "    image = tf.image.pad_to_bounding_box(\n",
        "        image, 0, 0, padded_image_shape[0], padded_image_shape[1]\n",
        "    )\n",
        "    return image, image_shape, ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-z7Sfdr2sLIc"
      },
      "outputs": [],
      "source": [
        "def convert_to_xywh(boxes):\n",
        "    return tf.concat(\n",
        "        [(boxes[..., :2] + boxes[..., 2:]) / 2.0, boxes[..., 2:] - boxes[..., :2]],\n",
        "        axis=-1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwHAsHcSsMgE"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(sample):\n",
        "    image = sample[\"image\"]\n",
        "    bbox = swap_xy(sample[\"objects\"][\"bbox\"])\n",
        "    class_id = tf.cast(sample[\"objects\"][\"type\"], dtype=tf.int32)\n",
        "\n",
        "    image, bbox = random_flip_horizontal(image, bbox)\n",
        "    image, image_shape, _ = resize_and_pad_image(image)\n",
        "\n",
        "    bbox = tf.stack(\n",
        "        [\n",
        "            bbox[:, 0] * image_shape[1],\n",
        "            bbox[:, 1] * image_shape[0],\n",
        "            bbox[:, 2] * image_shape[1],\n",
        "            bbox[:, 3] * image_shape[0],\n",
        "        ],\n",
        "        axis=-1,\n",
        "    )\n",
        "    bbox = convert_to_xywh(bbox)\n",
        "    return image, bbox, class_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KkOJIHtsN8Q"
      },
      "outputs": [],
      "source": [
        "class AnchorBox:\n",
        "    def __init__(self):\n",
        "        self.aspect_ratios = [0.5, 1.0, 2.0]\n",
        "        self.scales = [2 ** x for x in [0, 1 / 3, 2 / 3]]\n",
        "\n",
        "        self._num_anchors = len(self.aspect_ratios) * len(self.scales)\n",
        "        self._strides = [2 ** i for i in range(3, 8)]\n",
        "        self._areas = [x ** 2 for x in [32.0, 64.0, 128.0, 256.0, 512.0]]\n",
        "        self._anchor_dims = self._compute_dims()\n",
        "\n",
        "    def _compute_dims(self):\n",
        "        anchor_dims_all = []\n",
        "        for area in self._areas:\n",
        "            anchor_dims = []\n",
        "            for ratio in self.aspect_ratios:\n",
        "                anchor_height = tf.math.sqrt(area / ratio)\n",
        "                anchor_width = area / anchor_height\n",
        "                dims = tf.reshape(\n",
        "                    tf.stack([anchor_width, anchor_height], axis=-1), [1, 1, 2]\n",
        "                )\n",
        "                for scale in self.scales:\n",
        "                    anchor_dims.append(scale * dims)\n",
        "            anchor_dims_all.append(tf.stack(anchor_dims, axis=-2))\n",
        "        return anchor_dims_all\n",
        "\n",
        "    def _get_anchors(self, feature_height, feature_width, level):\n",
        "        rx = tf.range(feature_width, dtype=tf.float32) + 0.5\n",
        "        ry = tf.range(feature_height, dtype=tf.float32) + 0.5\n",
        "        centers = tf.stack(tf.meshgrid(rx, ry), axis=-1) * self._strides[level - 3]\n",
        "        centers = tf.expand_dims(centers, axis=-2)\n",
        "        centers = tf.tile(centers, [1, 1, self._num_anchors, 1])\n",
        "        dims = tf.tile(\n",
        "            self._anchor_dims[level - 3], [feature_height, feature_width, 1, 1]\n",
        "        )\n",
        "        anchors = tf.concat([centers, dims], axis=-1)\n",
        "        return tf.reshape(\n",
        "            anchors, [feature_height * feature_width * self._num_anchors, 4]\n",
        "        )\n",
        "\n",
        "    def get_anchors(self, image_height, image_width):\n",
        "        anchors = [\n",
        "            self._get_anchors(\n",
        "                tf.math.ceil(image_height / 2 ** i),\n",
        "                tf.math.ceil(image_width / 2 ** i),\n",
        "                i,\n",
        "            )\n",
        "            for i in range(3, 8)\n",
        "        ]\n",
        "        return tf.concat(anchors, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N18CXk2gsQWt"
      },
      "outputs": [],
      "source": [
        "def convert_to_corners(boxes):\n",
        "    return tf.concat(\n",
        "        [boxes[..., :2] - boxes[..., 2:] / 2.0, boxes[..., :2] + boxes[..., 2:] / 2.0],\n",
        "        axis=-1,\n",
        "    )\n",
        "\n",
        "def compute_iou(boxes1, boxes2):\n",
        "    boxes1_corners = convert_to_corners(boxes1)\n",
        "    boxes2_corners = convert_to_corners(boxes2)\n",
        "    lu = tf.maximum(boxes1_corners[:, None, :2], boxes2_corners[:, :2])\n",
        "    rd = tf.minimum(boxes1_corners[:, None, 2:], boxes2_corners[:, 2:])\n",
        "    intersection = tf.maximum(0.0, rd - lu)\n",
        "    intersection_area = intersection[:, :, 0] * intersection[:, :, 1]\n",
        "    boxes1_area = boxes1[:, 2] * boxes1[:, 3]\n",
        "    boxes2_area = boxes2[:, 2] * boxes2[:, 3]\n",
        "    union_area = tf.maximum(\n",
        "        boxes1_area[:, None] + boxes2_area - intersection_area, 1e-8\n",
        "    )\n",
        "    return tf.clip_by_value(intersection_area / union_area, 0.0, 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-PlOMMusRzu"
      },
      "outputs": [],
      "source": [
        "class LabelEncoder:\n",
        "\n",
        "    def __init__(self):\n",
        "        self._anchor_box = AnchorBox()\n",
        "        self._box_variance = tf.convert_to_tensor(\n",
        "            [0.1, 0.1, 0.2, 0.2], dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def _match_anchor_boxes(\n",
        "        self, anchor_boxes, gt_boxes, match_iou=0.5, ignore_iou=0.4\n",
        "    ):\n",
        "        iou_matrix = compute_iou(anchor_boxes, gt_boxes)\n",
        "        max_iou = tf.reduce_max(iou_matrix, axis=1)\n",
        "        matched_gt_idx = tf.argmax(iou_matrix, axis=1)\n",
        "        positive_mask = tf.greater_equal(max_iou, match_iou)\n",
        "        negative_mask = tf.less(max_iou, ignore_iou)\n",
        "        ignore_mask = tf.logical_not(tf.logical_or(positive_mask, negative_mask))\n",
        "        return (\n",
        "            matched_gt_idx,\n",
        "            tf.cast(positive_mask, dtype=tf.float32),\n",
        "            tf.cast(ignore_mask, dtype=tf.float32),\n",
        "        )\n",
        "\n",
        "    def _compute_box_target(self, anchor_boxes, matched_gt_boxes):\n",
        "        box_target = tf.concat(\n",
        "            [\n",
        "                (matched_gt_boxes[:, :2] - anchor_boxes[:, :2]) / anchor_boxes[:, 2:],\n",
        "                tf.math.log(matched_gt_boxes[:, 2:] / anchor_boxes[:, 2:]),\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "        box_target = box_target / self._box_variance\n",
        "        return box_target\n",
        "\n",
        "    def _encode_sample(self, image_shape, gt_boxes, cls_ids):\n",
        "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
        "        cls_ids = tf.cast(cls_ids, dtype=tf.float32)\n",
        "        matched_gt_idx, positive_mask, ignore_mask = self._match_anchor_boxes(\n",
        "            anchor_boxes, gt_boxes\n",
        "        )\n",
        "        matched_gt_boxes = tf.gather(gt_boxes, matched_gt_idx)\n",
        "        box_target = self._compute_box_target(anchor_boxes, matched_gt_boxes)\n",
        "        matched_gt_cls_ids = tf.gather(cls_ids, matched_gt_idx)\n",
        "        cls_target = tf.where(\n",
        "            tf.not_equal(positive_mask, 1.0), -1.0, matched_gt_cls_ids\n",
        "        )\n",
        "        cls_target = tf.where(tf.equal(ignore_mask, 1.0), -2.0, cls_target)\n",
        "        cls_target = tf.expand_dims(cls_target, axis=-1)\n",
        "        label = tf.concat([box_target, cls_target], axis=-1)\n",
        "        return label\n",
        "\n",
        "    def encode_batch(self, batch_images, gt_boxes, cls_ids):\n",
        "        images_shape = tf.shape(batch_images)\n",
        "        batch_size = images_shape[0]\n",
        "\n",
        "        labels = tf.TensorArray(dtype=tf.float32, size=batch_size, dynamic_size=True)\n",
        "        for i in range(batch_size):\n",
        "            label = self._encode_sample(images_shape, gt_boxes[i], cls_ids[i])\n",
        "            labels = labels.write(i, label)\n",
        "        batch_images = tf.keras.applications.resnet.preprocess_input(batch_images)\n",
        "        return batch_images, labels.stack()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3ugB9QLsTht"
      },
      "outputs": [],
      "source": [
        "class FeaturePyramid(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, backbone):\n",
        "        super(FeaturePyramid, self).__init__(name=\"FeaturePyramid\")\n",
        "        self.backbone = backbone\n",
        "        self.conv_c3_1x1 = tf.keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c4_1x1 = tf.keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c5_1x1 = tf.keras.layers.Conv2D(256, 1, 1, \"same\")\n",
        "        self.conv_c3_3x3 = tf.keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c4_3x3 = tf.keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c5_3x3 = tf.keras.layers.Conv2D(256, 3, 1, \"same\")\n",
        "        self.conv_c6_3x3 = tf.keras.layers.Conv2D(256, 3, 2, \"same\")\n",
        "        self.conv_c7_3x3 = tf.keras.layers.Conv2D(256, 3, 2, \"same\")\n",
        "        self.upsample_2x = tf.keras.layers.UpSampling2D(2)\n",
        "\n",
        "    def call(self, images, training=False):\n",
        "        c3_output, c4_output, c5_output = self.backbone(images, training=training)\n",
        "        p3_output = self.conv_c3_1x1(c3_output)\n",
        "        p4_output = self.conv_c4_1x1(c4_output)\n",
        "        p5_output = self.conv_c5_1x1(c5_output)\n",
        "        p4_output = p4_output + self.upsample_2x(p5_output)\n",
        "        p3_output = p3_output + self.upsample_2x(p4_output)\n",
        "        p3_output = self.conv_c3_3x3(p3_output)\n",
        "        p4_output = self.conv_c4_3x3(p4_output)\n",
        "        p5_output = self.conv_c5_3x3(p5_output)\n",
        "        p6_output = self.conv_c6_3x3(c5_output)\n",
        "        p7_output = self.conv_c7_3x3(tf.nn.relu(p6_output))\n",
        "        return p3_output, p4_output, p5_output, p6_output, p7_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZq6Zmx0sYHb"
      },
      "outputs": [],
      "source": [
        "def build_head(output_filters, bias_init):\n",
        "    head = tf.keras.Sequential([tf.keras.Input(shape=[None, None, 256])])\n",
        "    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n",
        "    for _ in range(4):\n",
        "        head.add(\n",
        "            tf.keras.layers.Conv2D(256, 3, padding=\"same\", kernel_initializer=kernel_init)\n",
        "        )\n",
        "        head.add(tf.keras.layers.ReLU())\n",
        "    head.add(\n",
        "        tf.keras.layers.Conv2D(\n",
        "            output_filters,\n",
        "            3,\n",
        "            1,\n",
        "            padding=\"same\",\n",
        "            kernel_initializer=kernel_init,\n",
        "            bias_initializer=bias_init,\n",
        "        )\n",
        "    )\n",
        "    return head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDOpkOCZsZWj"
      },
      "outputs": [],
      "source": [
        "def get_backbone():\n",
        "    backbone = tf.keras.applications.ResNet50(\n",
        "        include_top=False, input_shape=[None, None, 3]\n",
        "    )\n",
        "    c3_output, c4_output, c5_output = [\n",
        "        backbone.get_layer(layer_name).output\n",
        "        for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n",
        "    ]\n",
        "    return tf.keras.Model(\n",
        "        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8VbwJx4sajg"
      },
      "outputs": [],
      "source": [
        "class RetinaNet(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes, backbone):\n",
        "        super(RetinaNet, self).__init__(name=\"RetinaNet\")\n",
        "        self.fpn = FeaturePyramid(backbone)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n",
        "        self.cls_head = build_head(9 * num_classes, prior_probability)\n",
        "        self.box_head = build_head(9 * 4, \"zeros\")\n",
        "\n",
        "    def call(self, image, training=False):\n",
        "        features = self.fpn(image, training=training)\n",
        "        N = tf.shape(image)[0]\n",
        "        cls_outputs = []\n",
        "        box_outputs = []\n",
        "        for feature in features:\n",
        "            box_outputs.append(tf.reshape(self.box_head(feature), [N, -1, 4]))\n",
        "            cls_outputs.append(\n",
        "                tf.reshape(self.cls_head(feature), [N, -1, self.num_classes])\n",
        "            )\n",
        "        cls_outputs = tf.concat(cls_outputs, axis=1)\n",
        "        box_outputs = tf.concat(box_outputs, axis=1)\n",
        "        return tf.concat([box_outputs, cls_outputs], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI6ZsKNIscFJ"
      },
      "outputs": [],
      "source": [
        "class RetinaNetBoxLoss(tf.losses.Loss):\n",
        "\n",
        "    def __init__(self, delta):\n",
        "        super(RetinaNetBoxLoss, self).__init__(\n",
        "            reduction=\"none\", name=\"RetinaNetBoxLoss\"\n",
        "        )\n",
        "        self._delta = delta\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        difference = y_true - y_pred\n",
        "        absolute_difference = tf.abs(difference)\n",
        "        squared_difference = difference ** 2\n",
        "        loss = tf.where(\n",
        "            tf.less(absolute_difference, self._delta),\n",
        "            0.5 * squared_difference,\n",
        "            absolute_difference - 0.5,\n",
        "        )\n",
        "        return tf.reduce_sum(loss, axis=-1)\n",
        "\n",
        "\n",
        "class RetinaNetClassificationLoss(tf.losses.Loss):\n",
        "\n",
        "    def __init__(self, alpha, gamma):\n",
        "        super(RetinaNetClassificationLoss, self).__init__(\n",
        "            reduction=\"none\", name=\"RetinaNetClassificationLoss\"\n",
        "        )\n",
        "        self._alpha = alpha\n",
        "        self._gamma = gamma\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "            labels=y_true, logits=y_pred\n",
        "        )\n",
        "        probs = tf.nn.sigmoid(y_pred)\n",
        "        alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n",
        "        pt = tf.where(tf.equal(y_true, 1.0), probs, 1 - probs)\n",
        "        loss = alpha * tf.pow(1.0 - pt, self._gamma) * cross_entropy\n",
        "        return tf.reduce_sum(loss, axis=-1)\n",
        "\n",
        "\n",
        "class RetinaNetLoss(tf.losses.Loss):\n",
        "\n",
        "    def __init__(self, num_classes=8, alpha=0.25, gamma=2.0, delta=1.0):\n",
        "        super(RetinaNetLoss, self).__init__(reduction=\"auto\", name=\"RetinaNetLoss\")\n",
        "        self._clf_loss = RetinaNetClassificationLoss(alpha, gamma)\n",
        "        self._box_loss = RetinaNetBoxLoss(delta)\n",
        "        self._num_classes = num_classes\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
        "        box_labels = y_true[:, :, :4]\n",
        "        box_predictions = y_pred[:, :, :4]\n",
        "        cls_labels = tf.one_hot(\n",
        "            tf.cast(y_true[:, :, 4], dtype=tf.int32),\n",
        "            depth=self._num_classes,\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "        cls_predictions = y_pred[:, :, 4:]\n",
        "        positive_mask = tf.cast(tf.greater(y_true[:, :, 4], -1.0), dtype=tf.float32)\n",
        "        ignore_mask = tf.cast(tf.equal(y_true[:, :, 4], -2.0), dtype=tf.float32)\n",
        "        clf_loss = self._clf_loss(cls_labels, cls_predictions)\n",
        "        box_loss = self._box_loss(box_labels, box_predictions)\n",
        "        clf_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, clf_loss)\n",
        "        box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n",
        "        normalizer = tf.reduce_sum(positive_mask, axis=-1)\n",
        "        clf_loss = tf.math.divide_no_nan(tf.reduce_sum(clf_loss, axis=-1), normalizer)\n",
        "        box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n",
        "        loss = clf_loss + box_loss\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G2QCUtYsd3Z"
      },
      "outputs": [],
      "source": [
        "num_classes = 8\n",
        "batch_size = 4\n",
        "\n",
        "resnet50_backbone = get_backbone()\n",
        "loss_fn = RetinaNetLoss(num_classes)\n",
        "model = RetinaNet(num_classes, resnet50_backbone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXBOblNDsupG"
      },
      "outputs": [],
      "source": [
        "learning_rates = [2.5e-06, 0.000625, 0.00125, 0.0025, 0.00025, 2.5e-05]\n",
        "learning_rate_boundaries = [125, 250, 500, 240000, 360000]\n",
        "learning_rate_fn = tf.optimizers.schedules.PiecewiseConstantDecay(\n",
        "    boundaries=learning_rate_boundaries, values=learning_rates\n",
        ")\n",
        "optimizer = tf.optimizers.SGD(learning_rate=learning_rate_fn, momentum=0.9)\n",
        "model.compile(loss=loss_fn, optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CIYF7V2s7Fa"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "(train_dataset, val_dataset), dataset_info = tfds.load(\n",
        "    \"kitti\", split=[\"train\", \"validation\"], with_info=True, data_dir=path\n",
        ")\n",
        "\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "train_dataset = train_dataset.shuffle(8 * batch_size)\n",
        "train_dataset = train_dataset.padded_batch(\n",
        "    batch_size=batch_size, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
        ")\n",
        "train_dataset = train_dataset.map(\n",
        "    label_encoder.encode_batch, num_parallel_calls=autotune\n",
        ")\n",
        "train_dataset = train_dataset.prefetch(autotune)\n",
        "\n",
        "val_dataset = val_dataset.map(preprocess_data, num_parallel_calls=autotune)\n",
        "val_dataset = val_dataset.padded_batch(\n",
        "    batch_size=1, padding_values=(0.0, 1e-8, -1), drop_remainder=True\n",
        ")\n",
        "val_dataset = val_dataset.map(label_encoder.encode_batch, num_parallel_calls=autotune)\n",
        "val_dataset = val_dataset.prefetch(autotune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "egUlqw37tENA",
        "outputId": "887ff6d1-0cee-41cf-fd78-5cd87cd14d9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  52/1586 [..............................] - ETA: 32:21:29 - loss: 3.8746"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-366ce7173bce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model_dir = path_drive + '/checkpoint'\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(model_dir, \"weights\" + \"_epoch_{epoch}\"),\n",
        "        monitor=\"loss\",\n",
        "        save_best_only=False,\n",
        "        save_weights_only=True,\n",
        "        verbose=1,\n",
        "    )\n",
        "]\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "hist = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B0HZeJSgtgIu"
      },
      "outputs": [],
      "source": [
        "class DecodePredictions(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes=8,\n",
        "        confidence_threshold=0.05,\n",
        "        nms_iou_threshold=0.5,\n",
        "        max_detections_per_class=100,\n",
        "        max_detections=100,\n",
        "        box_variance=[0.1, 0.1, 0.2, 0.2]\n",
        "    ):\n",
        "        super(DecodePredictions, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.confidence_threshold = confidence_threshold\n",
        "        self.nms_iou_threshold = nms_iou_threshold\n",
        "        self.max_detections_per_class = max_detections_per_class\n",
        "        self.max_detections = max_detections\n",
        "\n",
        "        self._anchor_box = AnchorBox()\n",
        "        self._box_variance = tf.convert_to_tensor(\n",
        "            box_variance, dtype=tf.float32\n",
        "        )\n",
        "\n",
        "    def _decode_box_predictions(self, anchor_boxes, box_predictions):\n",
        "        boxes = box_predictions * self._box_variance\n",
        "        boxes = tf.concat(\n",
        "            [\n",
        "                boxes[:, :, :2] * anchor_boxes[:, :, 2:] + anchor_boxes[:, :, :2],\n",
        "                tf.math.exp(boxes[:, :, 2:]) * anchor_boxes[:, :, 2:],\n",
        "            ],\n",
        "            axis=-1,\n",
        "        )\n",
        "        boxes_transformed = convert_to_corners(boxes)\n",
        "        return boxes_transformed\n",
        "\n",
        "    def call(self, images, predictions):\n",
        "        image_shape = tf.cast(tf.shape(images), dtype=tf.float32)\n",
        "        anchor_boxes = self._anchor_box.get_anchors(image_shape[1], image_shape[2])\n",
        "        box_predictions = predictions[:, :, :4]\n",
        "        cls_predictions = tf.nn.sigmoid(predictions[:, :, 4:])\n",
        "        boxes = self._decode_box_predictions(anchor_boxes[None, ...], box_predictions)\n",
        "\n",
        "        return tf.image.combined_non_max_suppression(\n",
        "            tf.expand_dims(boxes, axis=2),\n",
        "            cls_predictions,\n",
        "            self.max_detections_per_class,\n",
        "            self.max_detections,\n",
        "            self.nms_iou_threshold,\n",
        "            self.confidence_threshold,\n",
        "            clip_boxes=False,\n",
        "        )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "[GD-6]Go_Stop.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}